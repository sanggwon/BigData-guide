## 7. word2vec

1. 경로

- 소스("https://github.com/sanggwon/BigData-guide/blob/main/모델%20생성/05.word2vec_files/word2vec.py")  

<hr/>
2. word2vec  

- 단어 벡터 간 유의미한 유사도를 반영할 수 있도록 단어의 의미를 수치화 할 수 있는 방법

<hr/>
3. Word2Vec 훈련시키기  

- size = 워드 벡터의 특징 값. 즉, 임베딩 된 벡터의 차원.
- window = 컨텍스트 윈도우 크기
- min_count = 단어 최소 빈도 수 제한 (빈도가 적은 단어들은 학습하지 않는다.)
- workers = 학습을 위한 프로세스 수
- sg = 0은 CBOW, 1은 Skip-gram.
```python
    for file in list_files:
        data = pd.read_csv(file)
        x_ = data.iloc[:,1].values
        for data in x_:
            tokenized_data.append(data.split(' '))

    model = gensim.models.Word2Vec(sentences = tokenized_data, size = 100, window = 5, min_count = 5, workers = 4, sg = 0)
```

<hr/>
4. 저장

```python
    model.save(save_path + '/word2vec.model')
```
