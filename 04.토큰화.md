## 4. 토큰화

1. 경로 :

- 모델 생성\02.tokenizer_files\mecab\naverMecab.py 

<hr/>
2. MeCab  

- 형태소 분석기  
- 형태소 사전(https://bitbucket.org/eunjeon/mecab-ko/downloads/)

```python
m = MeCab.Tagger('./mecab_dic/mecab-ko-dic')
```

<hr/>
3. 주 단위로 분리  
- 주 단위로 가장 많이 언급된 단어를 분류하기 위한 함수

```python
def week_no(y, m, d):
    def _ymd_to_datetime(y, m, d):
        s = f'{y:04d}-{m:02d}-{d:02d}'
        return datetime.strptime(s, '%Y-%m-%d')
    target_day = _ymd_to_datetime(y, m, d)
    firstday = target_day.replace(day=1)
    while firstday.weekday() != 0:
        firstday += timedelta(days=1)
    if target_day < firstday:
        return str(y) + '-' + str(m) + '-' + str(0)
    return str(y) + '-' + str(m) + '-' + str((target_day - firstday).days // 7 + 1)
```

<hr/>
4. 불용어 리스트  

- 사용하지 않는 단어 목록을 호출합니다.

```python
#불용어 리스트
def stopwords():
    currentpath = os.getcwd()
    with open(currentpath + '\\stopwords.txt', 'rt', encoding='UTF8') as f:
        stopwords = f.read().splitlines()
    return stopwords
```

<hr/>
5. 토큰화  

- 본문 내용 중 형태소 사전에 포함되어 있는 단어를 도출하고, 불용어 리스트에 포함되지 않는 단어만 표출합니다.
- 참고 사이트(https://wonhwa.tistory.com/49)
- 품사 태그표(http://kkma.snu.ac.kr/documents/?doc=postag)
- tag_classes에 호출하려는 품사 태그를 넣습니다.

```python
def file_to_ids(file, dir, dir2, week):
    category_, date_, content_ = ['날짜'], ['내용'], ['구분']
    #tags for tokenizer
    tag_classes = ['VV', 'VA', 'NNG+XS', 'NNG+VC', 'XR', 'NNG', 'NNP','VA', 'VV+EC', 'XSV+EP', 'XSV+EF', 'XSV+EC', 'VV+ETM', 'MAG', 'MAJ', 'NP', 'NNBC', 'IC', 'XR', 'VA+EC']
    #데이터 읽어오고.
    fname = target_path + dir + '/' + dir2 + '/' +file
    data = pd.read_csv(fname)
    #각각 분류
    title = data.iloc[:,0].values
    date = data.iloc[:, 1].values
    content = data.iloc[:, 2].values
    category = data.iloc[:, 3].values

    for cnt, value in tqdm(enumerate(title)):
        result = []
        value = m.parseToNode(str(title[cnt]).strip() + str(content[cnt]).strip())
        while value:
            tag = value.feature.split(",")[0]
            word = value.feature.split(",")[3]
            if tag in tag_classes:
                if word == "*": value = value.next
                result.append(word)
            value = value.next

        result = [word for word in result if not word in stopwords()] # 불용어 제거
        content_.append(' '.join(result))
        date_.append(date[cnt])
        category_.append(category[cnt])
    
    if not os.path.exists(save_path + week):
        os.mkdir(save_path + week)
    if not os.path.exists(save_path + week + '/' + dir2):
        os.mkdir(save_path + week + '/' + dir2)

    with open(save_path + week + '/' + dir2 + '/' + file, 'w+', encoding='utf-8-sig', newline='') as f:
        writer = csv.writer(f)
        for cnt, i in enumerate(content_):
            date__ = date_[cnt]
            content__ = content_[cnt]
            if content__ != '' :
                category__ = category_[cnt]
                writer.writerow((date__, content__, category__))
        f.truncate()
```
